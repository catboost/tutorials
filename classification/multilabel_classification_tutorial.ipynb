{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646b7c02",
   "metadata": {},
   "source": [
    "# Multi Label Binary Classification with CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e58119",
   "metadata": {},
   "source": [
    "CatBoost since the 1.0.0 version supports multilabel binary classification. A target for this mode is a matrix of size $NxK$ where $N$ is the number of objects and $K$ is the number of classes (a.k.a. labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9859fd",
   "metadata": {},
   "source": [
    "There are two loss functions for multilabel binary classification - $MultiLogloss$ and $MultiCrossEntropy$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f764c9d",
   "metadata": {},
   "source": [
    "For $MultiLogloss$ loss function $y_{ik}$ should be in $\\{0, 1\\}$:\n",
    "$$\n",
    "Y = \\begin{pmatrix}\n",
    "1 & 0 & 0 & ... & 1 & 1\\\\\n",
    "0 & 1 & 0 & ... & 1 & 0\\\\\n",
    "... & ... & ... & y_{ik} & ... & ...\\\\\n",
    "1 & 0 & 1 & ... & 0 & 1\\\\\n",
    "\\end{pmatrix}_{NxK}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db442169",
   "metadata": {},
   "source": [
    "For $MultiCrossEntropy$ loss function $y_{ik}$ should be in $[0, 1]$:\n",
    "$$\n",
    "Y = \\begin{pmatrix}\n",
    "0.2 & 0.8 & 0.0 & ... & 0.7 & 0.3\\\\\n",
    "0 & 0.6 & 0.3 & ... & 0.9 & 0.0\\\\\n",
    "... & ... & ... & y_{ik} & ... & ...\\\\\n",
    "1.0 & 0.0 & 0.3 & ... & 0.3 & 0.8\\\\\n",
    "\\end{pmatrix}_{NxK}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7dde7",
   "metadata": {},
   "source": [
    "The formula is the same for both loss functions:\n",
    "$$\n",
    "MultiLogloss = MultiCrossEntropy = \\displaystyle\\frac{-\\sum\\limits_{k=1}^{K} \\sum\\limits_{i=1}^{N} w_{i} (y_{ik} \\log p_{ik} + (1 - t_{ik}) \\log (1 - p_{ik}) )}{K\\sum\\limits_{i=1}^{N}w_{i}}{ ,}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  \\mbox{where }p_{ik} = \\sigma(a_{ik}) = \\frac{e^{a_{ik}}}{1 + e^{a_{ik}}}{ ,}\n",
    "$$\n",
    "\n",
    "$$\n",
    " a_{ik} \\mbox{- raw value of model for } i\\mbox{-th object and } j\\mbox{-th class}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7af97e",
   "metadata": {},
   "source": [
    "Let's try multilabel classification mode on synthetic dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb505a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6d256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from catboost.utils import eval_metric\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16a780",
   "metadata": {},
   "source": [
    "#### Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dab0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_multilabel_classification(n_samples=500, n_features=20, n_classes=5, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "train_pool = Pool(X_train, Y_train)\n",
    "test_pool = Pool(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17142e",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1652c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.033623\n",
      "0:\tlearn: 0.2778667\ttest: 0.3328000\tbest: 0.3328000 (0)\ttotal: 51ms\tremaining: 25.4s\n",
      "50:\tlearn: 0.0917333\ttest: 0.2496000\tbest: 0.2496000 (50)\ttotal: 135ms\tremaining: 1.19s\n",
      "100:\tlearn: 0.0432000\ttest: 0.2304000\tbest: 0.2304000 (100)\ttotal: 217ms\tremaining: 857ms\n",
      "150:\tlearn: 0.0160000\ttest: 0.2352000\tbest: 0.2304000 (100)\ttotal: 301ms\tremaining: 695ms\n",
      "200:\tlearn: 0.0058667\ttest: 0.2352000\tbest: 0.2304000 (100)\ttotal: 390ms\tremaining: 580ms\n",
      "250:\tlearn: 0.0016000\ttest: 0.2320000\tbest: 0.2304000 (100)\ttotal: 480ms\tremaining: 476ms\n",
      "300:\tlearn: 0.0000000\ttest: 0.2384000\tbest: 0.2304000 (100)\ttotal: 572ms\tremaining: 378ms\n",
      "350:\tlearn: 0.0000000\ttest: 0.2320000\tbest: 0.2304000 (100)\ttotal: 663ms\tremaining: 281ms\n",
      "400:\tlearn: 0.0000000\ttest: 0.2368000\tbest: 0.2304000 (100)\ttotal: 756ms\tremaining: 187ms\n",
      "450:\tlearn: 0.0000000\ttest: 0.2336000\tbest: 0.2304000 (100)\ttotal: 851ms\tremaining: 92.5ms\n",
      "499:\tlearn: 0.0000000\ttest: 0.2384000\tbest: 0.2304000 (100)\ttotal: 947ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2304\n",
      "bestIteration = 100\n",
      "\n",
      "Shrink model to first 101 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f14ab052b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(\n",
    "    loss_function='MultiLogloss',\n",
    "    eval_metric='HammingLoss',\n",
    "    iterations=500,\n",
    "    class_names=['A', 'B', 'C', 'D', 'E']\n",
    ")\n",
    "clf.fit(train_pool, eval_set=test_pool, metric_period=10, plot=True, verbose=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8586d7",
   "metadata": {},
   "source": [
    "#### Predict for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5516d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe47150",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dfa41",
   "metadata": {},
   "source": [
    "**Common deifinitions:**\n",
    "\n",
    "$N$ - the number of objects\n",
    "\n",
    "$K$ - the number of labels (classes)\n",
    "\n",
    "$y_{ik} \\in {0, 1}$ - the target value of k-th label for i-th object\n",
    "\n",
    "$c_{ik} \\in {0, 1}$ - the predicted value of k-th label for i-th object\n",
    "\n",
    "$p_{ik} \\in [0, 1]$ - the predicted probability of k-th label for i-th object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc6fbb",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245ad98",
   "metadata": {},
   "source": [
    "Classic accuracy for multilabel classifications for each object compares whole target vector with whole predicted vector:\n",
    "$$Accuracy_i = \n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "      1, \\mbox{if }\\forall k: c_{ik} = y_{ik} \\\\\n",
    "      0, \\mbox{otherwise}\n",
    "    \\end{cases}\\,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "And total accuracy is an average accuracy for all objects:\n",
    "$$Accuracy = \\frac{\\sum\\limits_{i=1}^{N} w_i Accuracy_i}{\\sum\\limits_{i=1}^{N} w_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a7a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.368\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval_metric(Y_test, test_predict, 'Accuracy')[0]\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be531af2",
   "metadata": {},
   "source": [
    "### Accuracy per class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756cfea",
   "metadata": {},
   "source": [
    "You may want to calculate accuracy for each class individually, then you should specify `type` parameter for Accuracy metric like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eddc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class A: 0.776\n",
      "Accuracy for class B: 0.712\n",
      "Accuracy for class C: 0.744\n",
      "Accuracy for class D: 0.776\n",
      "Accuracy for class E: 0.84\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class = eval_metric(Y_test, test_predict, 'Accuracy:type=PerClass')\n",
    "for cls, value in zip(clf.classes_, accuracy_per_class):\n",
    "    print(f'Accuracy for class {cls}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d734f4",
   "metadata": {},
   "source": [
    "Accuracy per class is usually better because it more sensible for model changes. But we can't use it as `eval_metric` for early stopping and best model selection, because it returns several values.\n",
    "Instead of accuracy per class we can use $HammingLoss$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022327",
   "metadata": {},
   "source": [
    "### HammingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818864d",
   "metadata": {},
   "source": [
    "Essentially $HammingLoss$ is a mean accuracy per class subtracted from $1$. So the lower value of HammingLoss is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e9503",
   "metadata": {},
   "source": [
    "$$\n",
    "HammingLoss = \\frac{\\sum\\limits_{i=1}^{N} \\sum\\limits_{j=1}^{K} I(c_{ik}, y_{ik})}{NK}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mbox{where } I(c, y) = \n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "      1, \\mbox{if } c = y \\\\\n",
    "      0, \\mbox{otherwise}\n",
    "    \\end{cases}\\,\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ab8941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HammingLoss: 0.2304\n",
      "MeanAccuracyPerClass: 0.7696\n",
      "HammingLoss + MeanAccuracyPerClass = 1.0\n"
     ]
    }
   ],
   "source": [
    "hamming = eval_metric(Y_test, test_predict, 'HammingLoss')[0]\n",
    "print(f'HammingLoss: {hamming:.4f}')\n",
    "mean_accuracy_per_class = sum(accuracy_per_class) / len(accuracy_per_class)\n",
    "print(f'MeanAccuracyPerClass: {mean_accuracy_per_class:.4f}')\n",
    "print(f'HammingLoss + MeanAccuracyPerClass = {hamming + mean_accuracy_per_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363aea1",
   "metadata": {},
   "source": [
    "### Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cded4b",
   "metadata": {},
   "source": [
    "These metrics are calculated for each class individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b090dd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "class=A: 0.8333\n",
      "class=B: 0.6066\n",
      "class=C: 0.7826\n",
      "class=D: 0.8235\n",
      "class=E: 0.9655\n",
      "\n",
      "Recall\n",
      "class=A: 0.3750\n",
      "class=B: 0.7551\n",
      "class=C: 0.4000\n",
      "class=D: 0.5600\n",
      "class=E: 0.5957\n",
      "\n",
      "F1\n",
      "class=A: 0.5172\n",
      "class=B: 0.6727\n",
      "class=C: 0.5294\n",
      "class=D: 0.6667\n",
      "class=E: 0.7368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in ('Precision', 'Recall', 'F1'):\n",
    "    print(metric)\n",
    "    values = eval_metric(Y_test, test_predict, metric)\n",
    "    for cls, value in zip(clf.classes_, values):\n",
    "        print(f'class={cls}: {value:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7de41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
